<!DOCTYPE HTML>
<!--
	Hyperspace by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Mao Saeki</title>
		<meta name="google-site-verification" content="en5dvQeeKMiz4UekAlIjQPDDcQJLAs8BC5yASvGgZjM" />
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<!-- Google tag (gtag.js) -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-CNZRCSQZPB"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());

	  gtag('config', 'G-CNZRCSQZPB');
	</script>
	<body class="is-preload">

		<!-- Sidebar -->
			<section id="sidebar">
				<div class="inner">
					<nav>
						<ul>
							<li><a href="#about">About</a></li>
							<li><a href="#projects">Projects</a></li>
							<li><a href="#experiences">Experiences</a></li>
							<li><a href="#education">Educations</a></li>
							<li><a href="#awards">Awards</a></li>
							<li><a href="#publications">Publications</a></li>
							<li><a href="#contact">Contact</a></li>
						</ul>
					</nav>
				</div>
			</section>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Intro -->
					<section id="about" class="wrapper style1 fullscreen spotlights">
						<section>
							<a href="#" class="image"><img src="images/profile_pic_full.jpg" alt="" data-position="center center" /></a>
							<div class="content">
								<div class="inner">
									<h1>About</h1>
									<h2>Mao Saeki / 佐伯真於</h2>
									<p>I am a Ph.D. student in Computer Science at Waseda University, advised by <a href=http://www.pcl.cs.waseda.ac.jp/members/kobayashi/>Prof. Tetsunori Kobayashi</a>. 
										My interest lies in multimodal conversational AI, especially the understanding and generation of non-verbal cues.
										I am the lead developer of the <a href="#projects">InteLLA virtual agent</a>, and a founding member of <a href=https://www.equ.ai/>Equmenopolis Inc</a>.
									</p>
								</div>
							</div>
						</section>
					</section>

					<section id="projects" class="wrapper style2 fade-up">
						<div class="inner">
							<h2>Projects</h2>
							<p>
								<h3>InteteLLA - Intelligent Language Learning Assistant</h3>
								InteLLA automatically measures the conversational profiency of English learners through naturalistic conversation, enabled by gesture generation, turn-taking and proficiency assessment models.
								By adapting the conversational difficulty to each user though real time assessment, it is able to extract user's full potential, and give accurate assessment.
								InteLLA has previosly won the Bronze award at the QS-Wharton Reimagine Education Award 2021 in the Learning Assessment Category.
								<br><br>
								<b><i>We are actively looking for collaboraters! Contact me if you are interested.</i></b>
							</p>
							<iframe width="560" height="315" src="https://www.youtube.com/embed/RzCq5Z4cDBk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
							<iframe width="560" height="315" src="https://www.youtube.com/embed/Y50LtStPdP8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
						</div>
					</section>

				<!-- One -->
					<section id="experiences" class="wrapper style3 fade-up">
						<div class="inner">
							<h2>Experiences</h2>
							<p>
								<ul class="default">
									<li><b>Research Scientist</b>, Equmenopolis Inc., 2022 - Present</li>
									<li><b>Research Associate</b>, Waseda University, Perceptual Computing Group, 2020 - Present</li>
									<li><b>Research Assistant</b>, National Institute of Advanced Industrial Science and Technology, 2018 - 2019</li>
									<li><b>Development Intern</b>, LPixel Inc., 2018 - 2019</li>
								</ul>
							</p>
						</div>
					</section>

				<!-- Two -->
					<section id="education" class="wrapper style1 fade-up">
						<div class="inner">
							<h2>Education</h2>
							<p>
								<ul class="default">
									<li><b>Ph.D. in Computer Science and Engineering</b>, Waseda University, 2020 - Present (Advisor: Tetsunori Kobayashi)</li>
									<li><b>M.E. in Computer Science and Engineering</b>, Waseda University, 2020 (Advisor: Tetsunori Kobayashi)</li>
									<li><b>B.E. in Mechanical Engineering</b>, Waseda University, 2018</li>
								</ul>
							</p>
							<!-- <ul class="actions">
								<li><a href="generic.html" class="button">Learn more</a></li>
							</ul> -->
						</div>
					</section>

				<!-- Three -->
					<section id="awards" class="wrapper style2 fade-up">
						<div class="inner">
							<h2>Awards</h2>
							<p>
								<ul class="default">
									
									<li>
										<b>Best presentation</b>, The Japanese Society for Artificial Intelligence, June 2022<br>
										(Mao Saeki, Ryuki Matsuura, Shungo Suzuki, Kotoka Miyagi, Tetsunori Kobayashi, Yoichi Matsuyama, 
										InteLLA: A Speaking Proficiency Assessment Conversational Agent with Adaptive Interview Strategy, The Japanese Society for Artificial Intelligence (JSAI), SIG-SLUD, October 2021)
									</li>
									<li><b>Reimagine Education Award</b>, Learning Assessment Category Bronze, Quarrelli Simmons (QS) and The Wharton School of the University of Pennsylvania (MBA), December 2021
									<li>
										<b>Young Researcher Award for Excellent Research</b>, The Japanese Society for Artificial Intelligence SIG-SLUD (Special Interest Group of Speech, Language Understanding and Discourse Processing), October, 2021<br>
										(Mao Saeki, Ryuki Matsuura, Shungo Suzuki, Kotoka Miyagi, Tetsunori Kobayashi, Yoichi Matsuyama, 
										InteLLA: A Speaking Proficiency Assessment Conversational Agent with Adaptive Interview Strategy, The Japanese Society for Artificial Intelligence (JSAI), SIG-SLUD, October 2021)
									</li>
								</ul>
							</p>
							
						</div>
					</section>

					<section id="publications" class="wrapper style3 fade-up">
						<div class="inner">
							<h2>Publications</h2>
							<p>
								<ul class="default">
									<li>
										<b>Mao Saeki</b>, Kotoka Miyagi, Shinya Fujie, Shungo Suzuki, Tetsuji Ogawa, Tetsunori Kobayashi, and Yoichi Matsuyama, 
										"Confusion detection for adaptive conversational strategies of an oral proficiency assessment interview agent", 
										Proc. The 23rd Annual Conference of the International Speech Communication Association (INTERSPEECH2022), September 2022.
									</li>
									<li>
										Shungo Suzuki, Ryuki Matsuura, <b>Mao Saeki</b>, and Yoichi Matsuyama, 
										"How is dialogic fluency different from monologic fluency? The case of oral proficiency interview", 
										9th International Conference on Task-based language teaching (TBLT), August, 2022.
									</li>
									<li>
										Shungo Suzuki, Ryuki Matsuura, <b>Mao Saeki</b>, and Yoichi Matsuyama, 
										"Temporal features distinguish between second language oral proficiency levels? The case of Japanese learners of English", 
										31st annual conference of the European Second Language Association (EUROSLA), August 2022.
									</li>
									<li>
										Shungo Suzuki, Ryuki Matsuura, <b>Mao Saeki</b>, and Yoichi Matsuyama, 
										"Revisiting the assessment potential of read-aloud speech performance: Cognitive validity and predictive validity", 
										43rd Language Testing Research Colloquium (LTRC), March 2022
									</li>
									<li>
										Ryuki Matsuura, Shungo Suzuki, <b>Mao Saeki</b>, Tetsuji Ogawa, and Yoichi Matsuyama, 
										"Automated scoring of L2 fluency based on detection of disfluency words and pause locations", 
										Acoustic Society of Japan (ASJ), March 2022,
									</li>
									<li>
										<b>Mao Saeki</b>, Ryuki Matsuura, Shungo Suzuki, Kotoka Miyagi, Tetsunori Kobayashi, and Yoichi Matsuyama, 
										"InteLLA: A Speaking Proficiency Assessment Conversational Agent with Adaptive Interview Strategy", 
										The Japanese Society for Artificial Intelligence (JSAI), SIG-SLUD, October 2021.
									</li>
									<li>
										<b>Mao Saeki</b>, Weronika Demkow, Tetsunori Kobayashi, and Yoichi Matsuyama, 
										“A WoZ Study for an Incremental Proficiency Scoring Interview Agent Eliciting Ratable Samples“, 
										Proc. The 12th International Workshop on Spoken Dialog System Technology (IWSDS 2021), November 2021
									</li>
									<li>
										<b>Mao Saeki</b>, Yoichi Matsuyama, Satoshi Kobashikawa, Tetsuji Ogawa, and Tetsunori Kobayashi, 
										“Analysis of Multimodal Features for Speaking Proficiency Scoring in An Interview Dialogue“, 
										Proc. The 8th IEEE Spoken Language Technology Workshop (SLT 2021), pp.629-635, January 2021. 
									</li>
								</ul>
							</p>
						</div>
					</section>

					<section id="contact" class="wrapper style1 fade-up">
						<div class="inner">
							<h2>Contact</h2>
							<p>
								email: saeki[at]pcl.cs.waseda.ac.jp
							</p>
						</div>
					</section>

			</div>

		<!-- Footer -->
			<footer id="footer" class="wrapper style2-alt">
				<div class="inner">
					<ul class="menu">
						<li>Copyright © <script>document.write(new Date().getFullYear())</script> Mao Saeki</li>
					</ul>
				</div>
			</footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
